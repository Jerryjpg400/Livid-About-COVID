{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (Dense,LSTM,Concatenate,Layer,Lambda,\n",
    "                          Input,Multiply,SimpleRNN,GRU,\n",
    "                          TimeDistributed)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "DATA_DIR = pjoin('..', 'data')\n",
    "MAX_CSV = pjoin(DATA_DIR, 'MaxV_10.csv')\n",
    "DAT_CSV = pjoin(DATA_DIR, 'Data319.csv')\n",
    "\n",
    "dataframeMV = pandas.read_csv(MAX_CSV, header=None, engine='python')\n",
    "datasetMV = dataframeMV.values\n",
    "datasetMV = datasetMV.astype('float32')\n",
    "maxA = datasetMV[0,:]\n",
    "maxT = datasetMV[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ns):\n",
    "    dataX, dataY = [], []\n",
    "    maxD = 0\n",
    "    minD = 10000\n",
    "    for c in ns:\n",
    "        dataframe = pandas.read_csv(DAT_CSV, usecols=[int(c)], engine='python')\n",
    "        dataframe.dropna(how='all',inplace=True)\n",
    "        dataset = dataframe.values\n",
    "        dataset = dataset.astype('float32')\n",
    "        sql = len(dataset)\n",
    "        if np.max(dataset) > maxD:\n",
    "            maxD = np.max(dataset)\n",
    "        if np.min(dataset) < minD:\n",
    "            minD = np.min(dataset)\n",
    "        a = dataset[:sql-1,0]\n",
    "        b = dataset[1:sql,0]\n",
    "        #a = np.reshape(a,(sql-1,1))\n",
    "        #b = np.reshape(b,(sql-1,1))\n",
    "        dataX.append(a)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY), minD, maxD\n",
    "\n",
    "def create_dataset_mscale(ns,maxDV,minD):\n",
    "    dataX, dataY = [], []\n",
    "    for c in ns:\n",
    "        #print(c)\n",
    "        dn = int(c/5)\n",
    "        #print(dn)\n",
    "        maxD = maxDV[dn]\n",
    "        dataframe = pandas.read_csv(DAT_CSV, usecols=[int(c)], engine='python')\n",
    "        dataframe.dropna(how='all',inplace=True)\n",
    "        dataset = dataframe.values\n",
    "        dataset = dataset.astype('float32')\n",
    "        dataset = (dataset - minD)/(maxD-minD)\n",
    "        sql = len(dataset)\n",
    "        a = dataset[:sql-1,0]\n",
    "        b = dataset[1:sql,0]\n",
    "        #a = np.reshape(a,(sql-1,1))\n",
    "        #b = np.reshape(b,(sql-1,1))\n",
    "        dataX.append(a)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActiveLoc = np.asarray(np.linspace(0,235,48))\n",
    "#ActiveLoc = [200]\n",
    "TotalLoc = np.asarray(ActiveLoc) + 1\n",
    "PopLoc = np.asarray(ActiveLoc) + 3\n",
    "MedLoc = np.asarray(ActiveLoc) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 5\n",
    "\n",
    "trainActive, targetActive = create_dataset_mscale(ActiveLoc,maxA,0)\n",
    "\n",
    "trainTotal, targetTotal = create_dataset_mscale(TotalLoc,maxT,0)\n",
    "\n",
    "trainPop, targetPop, minPop, maxPop = create_dataset(PopLoc)\n",
    "#maxPop = (np.max(targetPop))\n",
    "#minPop = np.min(trainPop)\n",
    "trainPop = (trainPop - minPop)/(maxPop - minPop)\n",
    "targetPop = (targetPop - minPop)/(maxPop - minPop)\n",
    "\n",
    "trainMed, targetMed, minMed, maxMed = create_dataset(MedLoc)\n",
    "#maxMed = np.max(targetMed)\n",
    "#minMed = np.min(trainMed)\n",
    "trainMed = (trainMed - minMed)/(maxMed - minMed)\n",
    "targetMed = (targetMed - minMed)/(maxMed - minMed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "HIn (Lambda)                    (None, None, 2)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "RecIn (Lambda)                  (None, None, 2)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 20)     60          HIn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 20)     1840        RecIn[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tile (Lambda)                   (None, None, 20)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 40)     0           lstm_1[0][0]                     \n",
      "                                                                 tile[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 2)      82          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,982\n",
      "Trainable params: 1,982\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AllInput = Input(shape=(None,4))\n",
    "RecInput = Lambda(lambda AllInput:AllInput[:,:,:2],name='RecIn')(AllInput)\n",
    "HidInput = Lambda(lambda AllInput:AllInput[:,-1:,2:],name='HIn')(AllInput)\n",
    "H = LSTM(\n",
    "    20, input_shape=(None,2), return_sequences=True\n",
    ")(RecInput)\n",
    "\n",
    "D2 = Dense(20,activation='softmax')(HidInput)\n",
    "# Duplicate for each timestep before concatenate\n",
    "D2 = Lambda(\n",
    "    lambda x: tf.tile(x, (1, tf.shape(H)[1], 1)),\n",
    "    name='tile'\n",
    ")(D2)\n",
    "Data = Concatenate()([H, D2])\n",
    "out = TimeDistributed(Dense(2,activation='relu'))(Data)\n",
    "\n",
    "CoVid = Model(AllInput,out)\n",
    "CoVid.summary()\n",
    "CoVid.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0.25505560636520386\n",
      "Epoch: 1\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "0.24671287834644318\n",
      "Epoch: 2\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.23851928114891052\n",
      "Epoch: 3\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.23050709068775177\n",
      "Epoch: 4\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.22269907593727112\n",
      "Epoch: 5\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.2151135504245758\n",
      "Epoch: 6\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.20777080953121185\n",
      "Epoch: 7\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.20069456100463867\n",
      "Epoch: 8\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.19391290843486786\n",
      "Epoch: 9\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.18745926022529602\n",
      "Epoch: 10\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.18137310445308685\n",
      "Epoch: 11\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "0.17570093274116516\n",
      "Epoch: 12\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.17049644887447357\n",
      "Epoch: 13\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.16582082211971283\n",
      "Epoch: 14\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.1617416888475418\n",
      "Epoch: 15\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15833042562007904\n",
      "Epoch: 16\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15565675497055054\n",
      "Epoch: 17\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15377862751483917\n",
      "Epoch: 18\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15272550284862518\n",
      "Epoch: 19\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15247315168380737\n",
      "Epoch: 20\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.1529131978750229\n",
      "Epoch: 21\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15383273363113403\n",
      "Epoch: 22\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "0.15493792295455933\n",
      "Epoch: 23\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.1559327244758606\n",
      "Epoch: 24\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "0.15660344064235687\n",
      "Epoch: 25\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.1568557322025299\n",
      "Epoch: 26\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.1567014753818512\n",
      "Epoch: 27\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15622229874134064\n",
      "Epoch: 28\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15553128719329834\n",
      "Epoch: 29\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.1547437608242035\n",
      "Epoch: 30\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15395821630954742\n",
      "Epoch: 31\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15324734151363373\n",
      "Epoch: 32\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15265583992004395\n",
      "Epoch: 33\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15220321714878082\n",
      "Epoch: 34\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15188908576965332\n",
      "Epoch: 35\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.1516992449760437\n",
      "Epoch: 36\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15161141753196716\n",
      "Epoch: 37\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "0.15159998834133148\n",
      "Epoch: 38\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.1516394019126892\n",
      "Epoch: 39\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15170663595199585\n",
      "Epoch: 40\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15178236365318298\n",
      "Epoch: 41\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15185166895389557\n",
      "Epoch: 42\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15190398693084717\n",
      "Epoch: 43\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15193286538124084\n",
      "Epoch: 44\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.1519353985786438\n",
      "Epoch: 45\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.15191175043582916\n",
      "Epoch: 46\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "0.15186433494091034\n",
      "Epoch: 47\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "0.1517973393201828\n"
     ]
    }
   ],
   "source": [
    "# Loop through each training curve from different regions\n",
    "# Treat each region as a single batch... \n",
    "# Reformat into trainX (1,time_steps,features) and trainY  (1, time_steps,features)\n",
    "\n",
    "for r in range(48):\n",
    "    print('Epoch:', r)\n",
    "    f1 = np.reshape(trainActive[0],(1,trainActive[0].shape[0],1))\n",
    "    f2 = np.reshape(trainTotal[0],(1,trainTotal[0].shape[0],1))\n",
    "    f3 = np.reshape(trainPop[0],(1,trainPop[0].shape[0],1))\n",
    "    f4 = np.reshape(trainMed[0],(1,trainMed[0].shape[0],1))\n",
    "    trainX = np.concatenate((f1,f2,f3,f4),axis=2)\n",
    "\n",
    "    t1 = np.reshape(targetActive[0],(1, targetActive[0].shape[0],1))\n",
    "    t2 = np.reshape(targetTotal[0],(1, targetTotal[0].shape[0],1))\n",
    "    trainY = np.concatenate((t1,t2),axis=2)\n",
    "    \n",
    "    CoVid.train_on_batch(trainX, trainY)\n",
    "    print(CoVid.evaluate(trainX, trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
